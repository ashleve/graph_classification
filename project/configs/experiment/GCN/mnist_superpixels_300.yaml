# @package _global_

# to execute this experiment run:
# python train.py logger=wandb +experiment/GCN_benchmarks=mnist_superpixels_300

defaults:
    - override /trainer: default_trainer.yaml
    - override /model: null
    - override /datamodule: null
    - override /callbacks: default_callbacks.yaml
    - override /logger: csv_logger.yaml

seed: 1234

trainer:
    min_epochs: 10
    max_epochs: 100
    accumulate_grad_batches: 1
    gradient_clip_val: 0.5

model:
    _target_: src.models.graph_classifier.GraphClassifier
    optimizer: adam
    lr: 0.001
    weight_decay: 0.0
    architecture: GCN
    node_features: ${datamodule.node_features}
    activation: "prelu"
    conv1_size: 64
    conv2_size: 128
    conv3_size: 512
    conv4_size: null
    pool_method: add
    use_batch_norm_after_pooling: False
    lin1_size: 128
    lin2_size: 64
    output_size: ${datamodule.classes}

datamodule:
    _target_: src.datamodules.mnist_superpixels_custom.MnistSuperpixelsCustomDataModule
    data_dir: ${data_dir}
    num_nodes: "300"
    batch_size: 32
    train_val_test_split: [55_000, 5_000, 10_000]
    node_features: 3
    classes: 10

logger:
    wandb:
        tags: ["mnist_sp_300"]
        notes: ""
        group: ""

callbacks:
    model_checkpoint:
        monitor: "val_acc"
        mode: "max"
    early_stopping:
        monitor: "val_loss"
        mode: "min"
