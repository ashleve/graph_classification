# @package _global_

# to execute this experiment run:
# python train.py logger=wandb +experiment/GAT_benchmarks=colors3

defaults:
    - override /trainer: default_trainer.yaml
    - override /model: null
    - override /datamodule: null
    - override /seeds: null
    - override /callbacks: wandb_callbacks.yaml
    - override /logger: wandb

seeds:
    pytorch_seed: 12345
    k_fold_split_seed: 12345

trainer:
    min_epochs: 10
    max_epochs: 100
    accumulate_grad_batches: 1
    gradient_clip_val: 0.5

model:
    _target_: src.models.graph_classifier.GraphClassifier
    optimizer: adam
    lr: 0.001
    weight_decay: 0.000001
    architecture: GAT
    num_node_features: 5
    num_classes: 11
    conv1_size: 32
    conv2_size: 64
    conv3_size: 128
    pool_method: max
    lin1_size: 64
    dropout1: 0.25

datamodule:
    _target_: src.datamodules.colors3.ColorsDataModule
    data_dir: ${data_dir}
    fold_num: ???
    num_splits: 10
    split_seed: ${seeds.k_fold_split_seed}
    batch_size: 32

logger:
    wandb:
        tags: ["colors3"]
        notes: ""
        group: ""
