{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch, DataLoader\n",
    "from torchvision.datasets import MNIST, CIFAR10, FashionMNIST\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# add directory above current directory to path\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = \"CIFAR10\"\n",
    "ADD_POSITION_TO_FEATURES = True\n",
    "DESIRED_NODES = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load img dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Reading dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Done.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(\"Reading dataset...\")\n",
    "\n",
    "if DATASET_NAME == \"MNIST\":\n",
    "    trainset = MNIST(\"../data\", download=True, train=True)\n",
    "    testset = MNIST(\"../data\", download=True, train=False)\n",
    "    \n",
    "elif DATASET_NAME == \"CIFAR10\":\n",
    "    trainset = CIFAR10(\"../data/CIFAR10\", download=True, train=True)\n",
    "    testset = CIFAR10(\"../data/CIFAR10\", download=True, train=False)\n",
    "    \n",
    "elif DATASET_NAME == \"FashionMNIST\":\n",
    "    trainset = FashionMNIST(\"../data\", download=True, train=True)\n",
    "    testset = FashionMNIST(\"../data\", download=True, train=False)\n",
    "    \n",
    "else:\n",
    "    print(\"Incorrect dataset name!\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "50000\n",
      "10000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Img shape: (32, 32, 3)\n",
      "Num of pixels per img: 1024\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "num_pixels = np.prod(trainset.data.shape[1:3])\n",
    "print(\"Img shape:\", trainset.data.shape[1:])\n",
    "print(\"Num of pixels per img:\", num_pixels)\n",
    "assert DESIRED_NODES < num_pixels, ('the number of superpixels cannot exceed the total number of pixels')\n",
    "assert DESIRED_NODES > 1, ('the number of superpixels cannot be too small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n",
      "(70000, 28, 28, 1)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "train_images = trainset.data\n",
    "test_images = testset.data\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "\n",
    "images = np.concatenate((train_images, test_images))\n",
    "if DATASET_NAME == \"MNIST\" or DATASET_NAME == \"FashionMNIST\":\n",
    "    images = np.reshape(images, (len(images), 28, 28, 1))\n",
    "print(images.shape)\n",
    "\n",
    "train_labels = trainset.targets\n",
    "test_labels = testset.targets\n",
    "labels = np.concatenate((train_labels, test_labels))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show one img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_img = images[7]\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test conversion on one img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(81, 3)\n",
      "(450, 2)\n",
      "(81, 2)\n"
     ]
    }
   ],
   "source": [
    "from utils.img_to_graph import convert_img_to_superpixels_graph\n",
    "\n",
    "\n",
    "x, edge_index, pos = convert_img_to_superpixels_graph(\n",
    "    test_img,\n",
    "    desired_nodes = DESIRED_NODES, \n",
    "    add_position_to_features=ADD_POSITION_TO_FEATURES\n",
    ")\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "print(edge_index.shape)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert img dataset to superpixel graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images into graphs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f723ba99e83c47dca6e63e9066e30496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=70000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Took 174.32199835777283s.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "\n",
    "# apply patch to enable progress bar with multiprocessing, requires python 3.8+\n",
    "# see https://stackoverflow.com/questions/57354700/starmap-combined-with-tqdm/57364423#57364423\n",
    "from utils.img_to_graph import better_istarmap\n",
    "multiprocessing.pool.Pool.istarmap = better_istarmap\n",
    "\n",
    "# method for img -> superpixel_graph conversion\n",
    "from utils.img_to_graph import convert_img_to_superpixels_graph\n",
    "\n",
    "# tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "print(\"Processing images into graphs...\")\n",
    "ptime = time.time()\n",
    "\n",
    "\n",
    "x_list = []\n",
    "edge_index_list = []\n",
    "pos_list = []\n",
    "slices = {\n",
    "    \"x\": [0],\n",
    "    \"edge_index\": [0],\n",
    "    \"pos\": [0],\n",
    "    \"y\": [0],\n",
    "}\n",
    "\n",
    "\n",
    "NUM_WORKERS = 6  # don't use too much or it will crash\n",
    "with multiprocessing.Pool(NUM_WORKERS) as pool:\n",
    "    args = list(zip(images, repeat(DESIRED_NODES), repeat(ADD_POSITION_TO_FEATURES)))\n",
    "    for graph in tqdm(pool.istarmap(convert_img_to_superpixels_graph, args), total=len(args)):\n",
    "        x, edge_index, pos = graph\n",
    "        \n",
    "        x = torch.as_tensor(x, dtype=torch.float32)\n",
    "        edge_index = torch.as_tensor(edge_index, dtype=torch.long)\n",
    "        pos = torch.as_tensor(pos, dtype=torch.float32)\n",
    "        \n",
    "        x_list.append(x)\n",
    "        edge_index_list.append(edge_index)\n",
    "        pos_list.append(pos)\n",
    "        \n",
    "        slices[\"x\"].append(slices[\"x\"][-1] + len(x))\n",
    "        slices[\"edge_index\"].append(slices[\"edge_index\"][-1] + len(edge_index))\n",
    "        slices[\"pos\"].append(slices[\"pos\"][-1] + len(pos))\n",
    "        slices[\"y\"].append(slices[\"y\"][-1] + 1)\n",
    "\n",
    "\n",
    "x_tensor = torch.cat(x_list, dim=0)\n",
    "edge_index_tensor = torch.cat(edge_index_list, dim=0).T\n",
    "pos_tensor = torch.cat(pos_list, dim=0)         \n",
    "y_tensor = torch.as_tensor(labels, dtype=torch.long)\n",
    "\n",
    "slices[\"x\"] = torch.as_tensor(slices[\"x\"], dtype=torch.long)\n",
    "slices[\"edge_index\"] = torch.as_tensor(slices[\"edge_index\"], dtype=torch.long)\n",
    "slices[\"pos\"] = torch.as_tensor(slices[\"pos\"], dtype=torch.long)\n",
    "slices[\"y\"] = torch.as_tensor(slices[\"y\"], dtype=torch.long)\n",
    "\n",
    "del x_list\n",
    "del edge_index_list\n",
    "del pos_list\n",
    "            \n",
    "\n",
    "ptime = time.time() - ptime\n",
    "print(f\"Took {ptime}s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5670000, 3])\n",
      "torch.Size([2, 31500000])\n",
      "torch.Size([5670000, 2])\n",
      "torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor.shape)\n",
    "print(edge_index_tensor.shape)\n",
    "print(pos_tensor.shape)\n",
    "print(y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 31500000], pos=[5670000, 2], x=[5670000, 3], y=[70000])\n"
     ]
    }
   ],
   "source": [
    "data = Data(x=x_tensor, edge_index=edge_index_tensor, pos=pos_tensor, y=y_tensor)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset in PyTorch Geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../data/\" + DATASET_NAME + \"_superpixels_\" + str(DESIRED_NODES) + \"/\" + \"processed\" + \"/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "torch.save((data, slices), path + \"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}